{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EN0acEscRm1k"},"outputs":[],"source":["from sklearn import svm, metrics\n","from skimage.feature import local_binary_pattern\n","import numpy as np\n","import cv2\n","from os import listdir\n","from os.path import isfile, join\n","from google.colab import drive\n","from tensorflow.keras.applications.xception import Xception, preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.models import Model\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Definir la ruta de la carpeta con las imágenes\n","path = '/content/drive/MyDrive/Estudios/Máster IIR/Segundo cuatrimestre/Proyecto VAI-AAI/chest_xray'\n","\n","# Categorías\n","categorias = ['NORMAL', 'PNEUMONIA']\n","\n","# Definir el modelo Xception con los pesos preentrenados y extrayendo características antes de las capas fully-connected\n","base_model = Xception(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n","# Aquí se podría utilizar base_model directamente, o agregar alguna capa global de pooling si es necesario\n","model = Model(inputs=base_model.input, outputs=base_model.output)\n","\n","def cargar_datos(ruta, size=(128, 128)):\n","    datos = []\n","    etiquetas = []\n","    for i, cat in enumerate(categorias):\n","        carpeta = join(ruta, cat)\n","        archivos = [f for f in listdir(carpeta) if isfile(join(carpeta, f))]\n","        for archivo in archivos:\n","            imagen_path = join(carpeta, archivo)\n","            imagen = cv2.imread(imagen_path)\n","            if imagen is None:\n","                print(f'No se pudo leer la imagen: {imagen_path}')\n","                continue\n","\n","            # Redimensionar imagen y realizar preprocesamiento necesario para Xception\n","            imagen = cv2.resize(imagen, size)\n","            imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n","            imagen = img_to_array(imagen)\n","            imagen = np.expand_dims(imagen, axis=0)\n","            imagen = preprocess_input(imagen)\n","\n","            # Extraer características con Xception\n","            caracteristicas = model.predict(imagen)\n","            caracteristicas = caracteristicas.flatten()  # Aplanar las características para usarlas en el SVM\n","\n","            datos.append(caracteristicas)\n","            etiquetas.append(i)\n","\n","    if len(datos) == 0 or len(etiquetas) == 0:\n","        raise ValueError(\"No se pudieron cargar los datos. Asegúrate de que la ruta y las categorías son correctas.\")\n","\n","    return np.array(datos), np.array(etiquetas)\n","\n","# Cargar datos de entrenamiento, validación y prueba\n","datos_entrenamiento, etiquetas_entrenamiento = cargar_datos(join(path, 'train'))\n","datos_prueba, etiquetas_prueba = cargar_datos(join(path, 'test'))\n","\n","# Asegurarse de que hay datos para al menos dos clases\n","if len(np.unique(etiquetas_entrenamiento)) < 2 or len(np.unique(etiquetas_prueba)) < 2:\n","    raise ValueError(\"Se debe cargar datos para al menos dos clases en cada conjunto de datos.\")\n","\n","# Crear y entrenar el modelo SVM\n","modelo = svm.SVC(gamma='scale')\n","modelo.fit(datos_entrenamiento, etiquetas_entrenamiento)\n","\n","# Evaluar el modelo\n","etiquetas_predichas = modelo.predict(datos_prueba)\n","precision = metrics.accuracy_score(etiquetas_prueba, etiquetas_predichas) * 100\n","print(f'Precisión del modelo: {precision:.2f}%')"]}]}