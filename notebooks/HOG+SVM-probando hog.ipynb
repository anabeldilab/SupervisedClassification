{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":146322,"status":"error","timestamp":1710345740704,"user":{"displayName":"Anabel Díaz Labrador","userId":"11823624713775819332"},"user_tz":-60},"id":"dUCynuc_layU","outputId":"25de4a56-d620-447a-8218-437da10ce24c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [8, (8, 8), 73.87820512820514, 98.71794871794873, 32.47863247863248, 70.90239410681399, 0.8252947481243301, 0.9165461319307473]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [8, (6, 6), 72.91666666666666, 98.2051282051282, 30.76923076923077, 70.27522935779817, 0.8192513368983957, 0.921356563664256]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [8, (7, 7), 74.51923076923077, 98.97435897435898, 33.76068376068376, 71.34935304990758, 0.8292158968850698, 0.9132478632478632]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [8, (8, 8), 73.87820512820514, 98.71794871794873, 32.47863247863248, 70.90239410681399, 0.8252947481243301, 0.9165461319307473]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [8, (9, 9), 73.87820512820514, 98.71794871794873, 32.47863247863248, 70.90239410681399, 0.8252947481243301, 0.9117795310103002]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [8, (6, 6), 72.91666666666666, 98.2051282051282, 30.76923076923077, 70.27522935779817, 0.8192513368983957, 0.921356563664256]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [8, (7, 7), 74.51923076923077, 98.97435897435898, 33.76068376068376, 71.34935304990758, 0.8292158968850698, 0.9132478632478632]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m modelo\u001b[38;5;241m.\u001b[39mfit(datos_entrenamiento, etiquetas_entrenamiento)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m etiquetas_predichas \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatos_prueba\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m exactitud \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(etiquetas_prueba, etiquetas_predichas)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Obtener la matriz de confusión\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Anabel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:814\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    812\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 814\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n","File \u001b[1;32mc:\\Users\\Anabel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:431\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    430\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Anabel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:450\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    443\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be equal to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    444\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of samples at training time\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    446\u001b[0m         )\n\u001b[0;32m    448\u001b[0m svm_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dual_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msvm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Importar las bibliotecas necesarias\n","from sklearn import svm, metrics\n","from skimage.feature import hog\n","import numpy as np\n","import cv2\n","from os import listdir, SEEK_END\n","from os.path import isfile, join\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n","import csv\n","import concurrent.futures\n","\n","# Definir la ruta de la carpeta con las imágenes\n","path = '../data'\n","\n","# Categorías\n","categorias = ['NORMAL', 'PNEUMONIA']\n","\n","# Lista de hiperparámetros HOG para probar\n","combinaciones_hog = [\n","    #{'orientations': 4, 'pixels_per_cell': (8, 8)},\n","    #{'orientations': 5, 'pixels_per_cell': (8, 8)},\n","    #{'orientations': 6, 'pixels_per_cell': (8, 8)},\n","    #{'orientations': 7, 'pixels_per_cell': (8, 8)},\n","    {'orientations': 8, 'pixels_per_cell': (8, 8)},\n","    #{'orientations': 9, 'pixels_per_cell': (8, 8)},\n","]\n","\n","total_data = []\n","\n","def procesar_imagen(imagen_path, hog_params, size, etiqueta):\n","    imagen = cv2.imread(imagen_path, cv2.IMREAD_GRAYSCALE)\n","    if imagen is None:\n","        print(f'No se pudo leer la imagen: {imagen_path}')\n","        return None, None\n","\n","    imagen = cv2.resize(imagen, size)\n","    fd = hog(imagen, orientations=hog_params['orientations'], pixels_per_cell=hog_params['pixels_per_cell'],\n","             cells_per_block=(1, 1), visualize=False)\n","\n","    return fd, etiqueta\n","\n","def cargar_datos(ruta, hog_params, size=(128, 128)):\n","    datos = []\n","    etiquetas = []\n","    with concurrent.futures.ThreadPoolExecutor() as executor:\n","        futures = []\n","        for i, cat in enumerate(categorias):\n","            carpeta = join(ruta, cat)\n","            archivos = [f for f in listdir(carpeta) if isfile(join(carpeta, f))]\n","            for archivo in archivos:\n","                imagen_path = join(carpeta, archivo)\n","                futures.append(executor.submit(procesar_imagen, imagen_path, hog_params, size, i))\n","\n","        for future in concurrent.futures.as_completed(futures):\n","            fd, label = future.result()\n","            if fd is not None:\n","                datos.append(fd)\n","                etiquetas.append(label)\n","\n","    if len(datos) == 0 or len(etiquetas) == 0:\n","        raise ValueError(\"No se pudieron cargar los datos. Asegúrate de que la ruta y las categorías son correctas.\")\n","\n","    return np.array(datos), np.array(etiquetas)\n","\n","\n","for hog_params in combinaciones_hog:\n","  # Cargar datos de entrenamiento, validación y prueba\n","  datos_entrenamiento, etiquetas_entrenamiento = cargar_datos(join(path, 'train'), hog_params)\n","  datos_prueba, etiquetas_prueba = cargar_datos(join(path, 'test'), hog_params)\n","\n","  # Asegurarse de que hay datos para al menos dos clases\n","  if len(np.unique(etiquetas_entrenamiento)) < 2 or len(np.unique(etiquetas_prueba)) < 2:\n","      raise ValueError(\"Se debe cargar datos para al menos dos clases en cada conjunto de datos.\")\n","\n","  # Crear y entrenar el modelo SVM\n","  modelo = svm.SVC(random_state=42) \n","  modelo.fit(datos_entrenamiento, etiquetas_entrenamiento)\n","\n","  # Evaluar el modelo\n","  etiquetas_predichas = modelo.predict(datos_prueba)\n","  exactitud = metrics.accuracy_score(etiquetas_prueba, etiquetas_predichas)\n","\n","  # Obtener la matriz de confusión\n","  cm = confusion_matrix(etiquetas_prueba, etiquetas_predichas)\n","\n","  # Calcular Sensibilidad (Recall) y Especificidad\n","  sensibilidad = recall_score(etiquetas_prueba, etiquetas_predichas)\n","  especificidad = cm[0,0] / (cm[0,0] + cm[0,1])\n","\n","  # Calcular Precisión y F1-Score\n","  precision = precision_score(etiquetas_prueba, etiquetas_predichas)\n","  f1 = f1_score(etiquetas_prueba, etiquetas_predichas)\n","\n","  # Calcular AUC\n","  # AUC requiere las puntuaciones o probabilidades de clase positiva, no las etiquetas predichas.\n","  # Asegúrate de que tu modelo soporte `decision_function` o `predict_proba`.\n","  if hasattr(modelo, \"decision_function\"):\n","      scores = modelo.decision_function(datos_prueba)\n","  else:\n","      scores = modelo.predict_proba(datos_prueba)[:, 1]\n","  auc = roc_auc_score(etiquetas_prueba, scores)\n","\n","\n","  current_data = {\n","    'Exactitud': exactitud * 100,\n","    'Sensibilidad': sensibilidad * 100,\n","    'Especificidad': especificidad * 100,\n","    'Precisión': precision * 100,\n","    'F1-Score': f1,\n","    'AUC': auc\n","  }\n","\n","  total_data.append(current_data)\n","\n","  #nombre_archivo_csv = '/content/drive/MyDrive/Estudios/Máster IIR/Segundo cuatrimestre/Proyecto VAI-AAI/first_version/hog.csv'\n","  nombre_archivo_csv = \"../results/hog_combination_svm.csv\"\n","\n","\n","  with open(nombre_archivo_csv, 'a+', newline='') as archivo:\n","      es_vacio = archivo.tell() == 0\n","      escritor = csv.writer(archivo)\n","\n","      # Suponiendo que es_vacio indica si debemos escribir los encabezados\n","      if es_vacio:\n","          # Escribir los nombres de las claves del diccionario y luego los nombres de las métricas\n","          escritor.writerow(list(hog_params.keys()) + list(current_data.keys()))\n","\n","      # Escribir los valores del diccionario y luego los valores de las métricas\n","      escritor.writerow(list(hog_params.values()) + list(current_data.values()))\n","\n","  print(\"Datos guardados en el archivo CSV.\")\n","  print(\"Claves:\", list(hog_params.keys()) + list(current_data.keys()))\n","  print(\"Valores:\", list(hog_params.values()) + list(current_data.values()))\n","\n","  if len(total_data) == len(combinaciones_hog):\n","    # Encuentra el índice del mejor F1-Score\n","    index_mejor_f1 = max(range(len(total_data)), key=lambda i: total_data[i]['F1-Score'])\n","\n","    # Encuentra la configuración HOG correspondiente al mejor F1-Score\n","    hog_correspondiente = combinaciones_hog[index_mejor_f1]\n","\n","    for i in range(6, 10):\n","      data = {\n","        'orientations': hog_correspondiente['orientations'],\n","        'pixels_per_cell': (i, i)\n","      }\n","      combinaciones_hog.append(data)\n","\n"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
