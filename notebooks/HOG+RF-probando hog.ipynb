{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":146322,"status":"error","timestamp":1710345740704,"user":{"displayName":"Anabel Díaz Labrador","userId":"11823624713775819332"},"user_tz":-60},"id":"dUCynuc_layU","outputId":"25de4a56-d620-447a-8218-437da10ce24c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [7, (8, 8), 71.31410256410257, 98.97435897435898, 25.213675213675213, 68.80570409982175, 0.8117770767613038, 0.8904010519395136]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [7, (6, 6), 70.67307692307693, 98.97435897435898, 23.504273504273502, 68.31858407079646, 0.8083769633507853, 0.8763423186500109]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [7, (7, 7), 72.11538461538461, 99.23076923076923, 26.923076923076923, 69.35483870967742, 0.8164556962025317, 0.8792844619767697]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [7, (8, 8), 73.5576923076923, 98.97435897435898, 31.196581196581196, 70.56672760511883, 0.823906083244397, 0.8933651106728029]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [7, (9, 9), 70.83333333333334, 98.97435897435898, 23.931623931623932, 68.43971631205675, 0.8092243186582809, 0.894017094017094]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [7, (6, 6), 71.47435897435898, 98.71794871794873, 26.06837606837607, 68.99641577060932, 0.8122362869198312, 0.8819471838702608]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [7, (7, 7), 71.47435897435898, 99.23076923076923, 25.213675213675213, 68.86120996441281, 0.8130252100840336, 0.8857714223098838]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [7, (8, 8), 71.7948717948718, 98.97435897435898, 26.495726495726498, 69.17562724014337, 0.8143459915611815, 0.8883519614288845]\n","Datos guardados en el archivo CSV.\n","Claves: ['orientations', 'pixels_per_cell', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [7, (9, 9), 72.75641025641025, 99.23076923076923, 28.63247863247863, 69.85559566787003, 0.8199152542372882, 0.8993754109138725]\n"]}],"source":["# Importar las bibliotecas necesarias\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from skimage.feature import hog\n","import numpy as np\n","import cv2\n","from os import listdir\n","from os.path import isfile, join\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n","import csv\n","import concurrent.futures\n","\n","# Definir la ruta de la carpeta con las imágenes\n","#path = '/content/drive/MyDrive/Estudios/Máster IIR/Segundo cuatrimestre/Proyecto VAI-AAI/chest_xray'\n","path = '../data'\n","\n","# Categorías\n","categorias = ['NORMAL', 'PNEUMONIA']\n","\n","# Lista de hiperparámetros HOG para probar\n","combinaciones_hog = [\n","    #{'orientations': 4, 'pixels_per_cell': (8, 8)},\n","    #{'orientations': 5, 'pixels_per_cell': (8, 8)},\n","    #{'orientations': 6, 'pixels_per_cell': (8, 8)},\n","    {'orientations': 7, 'pixels_per_cell': (8, 8)},\n","    #{'orientations': 8, 'pixels_per_cell': (8, 8)},\n","    #{'orientations': 9, 'pixels_per_cell': (8, 8)},\n","]\n","\n","total_data = []\n","\n","def procesar_imagen(imagen_path, hog_params, size, etiqueta):\n","    imagen = cv2.imread(imagen_path, cv2.IMREAD_GRAYSCALE)\n","    if imagen is None:\n","        print(f'No se pudo leer la imagen: {imagen_path}')\n","        return None, None\n","\n","    imagen = cv2.resize(imagen, size)\n","    fd = hog(imagen, orientations=hog_params['orientations'], pixels_per_cell=hog_params['pixels_per_cell'],\n","             cells_per_block=(1, 1), visualize=False)\n","\n","    return fd, etiqueta\n","\n","def cargar_datos(ruta, hog_params, size=(128, 128)):\n","    datos = []\n","    etiquetas = []\n","    with concurrent.futures.ThreadPoolExecutor() as executor:\n","        futures = []\n","        for i, cat in enumerate(categorias):\n","            carpeta = join(ruta, cat)\n","            archivos = [f for f in listdir(carpeta) if isfile(join(carpeta, f))]\n","            for archivo in archivos:\n","                imagen_path = join(carpeta, archivo)\n","                futures.append(executor.submit(procesar_imagen, imagen_path, hog_params, size, i))\n","\n","        for future in concurrent.futures.as_completed(futures):\n","            fd, label = future.result()\n","            if fd is not None:\n","                datos.append(fd)\n","                etiquetas.append(label)\n","\n","    if len(datos) == 0 or len(etiquetas) == 0:\n","        raise ValueError(\"No se pudieron cargar los datos. Asegúrate de que la ruta y las categorías son correctas.\")\n","\n","    return np.array(datos), np.array(etiquetas)\n","\n","\n","for hog_params in combinaciones_hog:\n","  # Cargar datos de entrenamiento, validación y prueba\n","  datos_entrenamiento, etiquetas_entrenamiento = cargar_datos(join(path, 'train'), hog_params)\n","  datos_prueba, etiquetas_prueba = cargar_datos(join(path, 'test'), hog_params)\n","\n","  # Asegurarse de que hay datos para al menos dos clases\n","  if len(np.unique(etiquetas_entrenamiento)) < 2 or len(np.unique(etiquetas_prueba)) < 2:\n","      raise ValueError(\"Se debe cargar datos para al menos dos clases en cada conjunto de datos.\")\n","\n","  # Crear y entrenar el modelo RF\n","  modelo = RandomForestClassifier(random_state=42, n_jobs=-1)\n","  modelo.fit(datos_entrenamiento, etiquetas_entrenamiento)\n","\n","  # Evaluar el modelo\n","  etiquetas_predichas = modelo.predict(datos_prueba)\n","  exactitud = metrics.accuracy_score(etiquetas_prueba, etiquetas_predichas)\n","\n","  # Obtener la matriz de confusión\n","  cm = confusion_matrix(etiquetas_prueba, etiquetas_predichas)\n","\n","  # Calcular Sensibilidad (Recall) y Especificidad\n","  sensibilidad = recall_score(etiquetas_prueba, etiquetas_predichas)\n","  especificidad = cm[0,0] / (cm[0,0] + cm[0,1])\n","\n","  # Calcular Precisión y F1-Score\n","  precision = precision_score(etiquetas_prueba, etiquetas_predichas)\n","  f1 = f1_score(etiquetas_prueba, etiquetas_predichas)\n","\n","  # Calcular AUC\n","  # AUC requiere las puntuaciones o probabilidades de clase positiva, no las etiquetas predichas.\n","  # Asegúrate de que tu modelo soporte `decision_function` o `predict_proba`.\n","  if hasattr(modelo, \"decision_function\"):\n","      scores = modelo.decision_function(datos_prueba)\n","  else:\n","      scores = modelo.predict_proba(datos_prueba)[:, 1]\n","  auc = roc_auc_score(etiquetas_prueba, scores)\n","\n","\n","  current_data = {\n","    'Exactitud': exactitud * 100,\n","    'Sensibilidad': sensibilidad * 100,\n","    'Especificidad': especificidad * 100,\n","    'Precisión': precision * 100,\n","    'F1-Score': f1,\n","    'AUC': auc\n","  }\n","\n","  total_data.append(current_data)\n","\n","  nombre_archivo_csv = \"../results/hog_combination_rf.csv\"\n","\n","\n","  with open(nombre_archivo_csv, 'a+', newline='') as archivo:\n","      es_vacio = archivo.tell() == 0\n","      escritor = csv.writer(archivo)\n","\n","      # Suponiendo que es_vacio indica si debemos escribir los encabezados\n","      if es_vacio:\n","          # Escribir los nombres de las claves del diccionario y luego los nombres de las métricas\n","          escritor.writerow(list(hog_params.keys()) + list(current_data.keys()))\n","\n","      # Escribir los valores del diccionario y luego los valores de las métricas\n","      escritor.writerow(list(hog_params.values()) + list(current_data.values()))\n","\n","  print(\"Datos guardados en el archivo CSV.\")\n","  print(\"Claves:\", list(hog_params.keys()) + list(current_data.keys()))\n","  print(\"Valores:\", list(hog_params.values()) + list(current_data.values()))\n","\n","  if len(total_data) == len(combinaciones_hog):\n","    # Encuentra el índice del mejor F1-Score\n","    index_mejor_f1 = max(range(len(total_data)), key=lambda i: total_data[i]['F1-Score'])\n","\n","    # Encuentra la configuración HOG correspondiente al mejor F1-Score\n","    hog_correspondiente = combinaciones_hog[index_mejor_f1]\n","\n","    for i in range(6, 10):\n","      data = {\n","        'orientations': hog_correspondiente['orientations'],\n","        'pixels_per_cell': (i, i)\n","      }\n","      combinaciones_hog.append(data)\n","\n"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
