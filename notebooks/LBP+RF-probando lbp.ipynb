{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":146322,"status":"error","timestamp":1710345740704,"user":{"displayName":"Anabel Díaz Labrador","userId":"11823624713775819332"},"user_tz":-60},"id":"dUCynuc_layU","outputId":"25de4a56-d620-447a-8218-437da10ce24c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Datos guardados en el archivo CSV.\n","Claves: ['radio', 'n_puntos', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [2, 16, 72.27564102564102, 96.41025641025641, 32.05128205128205, 70.2803738317757, 0.812972972972973, 0.8360344071882534]\n","Datos guardados en el archivo CSV.\n","Claves: ['radio', 'n_puntos', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [3, 24, 71.9551282051282, 97.17948717948718, 29.914529914529915, 69.79742173112339, 0.812433011789925, 0.8446088099934254]\n","Datos guardados en el archivo CSV.\n","Claves: ['radio', 'n_puntos', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [4, 32, 72.91666666666666, 96.41025641025641, 33.76068376068376, 70.80979284369114, 0.8165038002171553, 0.8594126671049748]\n","Datos guardados en el archivo CSV.\n","Claves: ['radio', 'n_puntos', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [4, 24, 73.5576923076923, 97.94871794871794, 32.9059829059829, 70.87198515769944, 0.8223896663078579, 0.8639820293666447]\n","Datos guardados en el archivo CSV.\n","Claves: ['radio', 'n_puntos', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [4, 28, 72.91666666666666, 96.66666666666667, 33.33333333333333, 70.73170731707317, 0.8169014084507042, 0.8612426035502958]\n","Datos guardados en el archivo CSV.\n","Claves: ['radio', 'n_puntos', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [4, 32, 73.87820512820514, 97.17948717948718, 35.04273504273504, 71.37476459510358, 0.8230184581976113, 0.8623000219154068]\n","Datos guardados en el archivo CSV.\n","Claves: ['radio', 'n_puntos', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","Valores: [4, 36, 73.3974358974359, 97.17948717948718, 33.76068376068376, 70.97378277153558, 0.8203463203463204, 0.8670666228358535]\n"]}],"source":["# Importar las bibliotecas necesarias\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from skimage.feature import local_binary_pattern\n","import numpy as np\n","import cv2\n","from os import listdir\n","from os.path import isfile, join\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n","import csv\n","import concurrent.futures\n","\n","# Definir la ruta de la carpeta con las imágenes\n","path = '../data'\n","\n","# Categorías\n","categorias = ['NORMAL', 'PNEUMONIA']\n","\n","# Lista de hiperparámetros HOG para probar\n","combinaciones_lbp = [\n","    {'radio': 1, 'n_puntos': 8 * 1},\n","    {'radio': 2, 'n_puntos': 8 * 2},\n","    {'radio': 3, 'n_puntos': 8 * 3},\n","    {'radio': 4, 'n_puntos': 8 * 4},\n","    {'radio': 5, 'n_puntos': 8 * 5},\n","]\n","\n","total_data = []\n","\n","def procesar_imagen(imagen_path, lbp_params, size, etiqueta):\n","    imagen = cv2.imread(imagen_path, cv2.IMREAD_GRAYSCALE)\n","    if imagen is None:\n","        print(f'No se pudo leer la imagen: {imagen_path}')\n","        return None, None\n","\n","    imagen = cv2.resize(imagen, size)\n","\n","    # Poner bien\n","    lbp = local_binary_pattern(imagen, lbp_params['n_puntos'], lbp_params['radio'], method='uniform')\n","    (hist, _) = np.histogram(lbp.ravel(),\n","                             bins=np.arange(0, lbp_params['n_puntos'] + 3),\n","                             range=(0, lbp_params['n_puntos'] + 2))\n","    hist = hist.astype(\"float\")\n","    hist /= (hist.sum() + 1e-7)\n","\n","    return hist, etiqueta\n","\n","def cargar_datos(ruta, lbp_params, size=(128, 128)):\n","    datos = []\n","    etiquetas = []\n","    with concurrent.futures.ThreadPoolExecutor() as executor:\n","        futures = []\n","        for i, cat in enumerate(categorias):\n","            carpeta = join(ruta, cat)\n","            archivos = [f for f in listdir(carpeta) if isfile(join(carpeta, f))]\n","            for archivo in archivos:\n","                imagen_path = join(carpeta, archivo)\n","                futures.append(executor.submit(procesar_imagen, imagen_path, lbp_params, size, i))\n","\n","        for future in concurrent.futures.as_completed(futures):\n","            fd, label = future.result()\n","            if fd is not None:\n","                datos.append(fd)\n","                etiquetas.append(label)\n","\n","    if len(datos) == 0 or len(etiquetas) == 0:\n","        raise ValueError(\"No se pudieron cargar los datos. Asegúrate de que la ruta y las categorías son correctas.\")\n","\n","    return np.array(datos), np.array(etiquetas)\n","\n","\n","for lbp_params in combinaciones_lbp:\n","  # Cargar datos de entrenamiento, validación y prueba\n","  datos_entrenamiento, etiquetas_entrenamiento = cargar_datos(join(path, 'train'), lbp_params)\n","  datos_prueba, etiquetas_prueba = cargar_datos(join(path, 'test'), lbp_params)\n","\n","  # Asegurarse de que hay datos para al menos dos clases\n","  if len(np.unique(etiquetas_entrenamiento)) < 2 or len(np.unique(etiquetas_prueba)) < 2:\n","      raise ValueError(\"Se debe cargar datos para al menos dos clases en cada conjunto de datos.\")\n","\n","  # Crear y entrenar el modelo RF\n","  modelo = RandomForestClassifier(random_state=42, n_jobs=-1)\n","  modelo.fit(datos_entrenamiento, etiquetas_entrenamiento)\n","\n","  # Evaluar el modelo\n","  etiquetas_predichas = modelo.predict(datos_prueba)\n","  exactitud = metrics.accuracy_score(etiquetas_prueba, etiquetas_predichas)\n","\n","  # Obtener la matriz de confusión\n","  cm = confusion_matrix(etiquetas_prueba, etiquetas_predichas)\n","\n","  # Calcular Sensibilidad (Recall) y Especificidad\n","  sensibilidad = recall_score(etiquetas_prueba, etiquetas_predichas)\n","  especificidad = cm[0,0] / (cm[0,0] + cm[0,1])\n","\n","  # Calcular Precisión y F1-Score\n","  precision = precision_score(etiquetas_prueba, etiquetas_predichas)\n","  f1 = f1_score(etiquetas_prueba, etiquetas_predichas)\n","\n","  # Calcular AUC\n","  # AUC requiere las puntuaciones o probabilidades de clase positiva, no las etiquetas predichas.\n","  # Asegúrate de que tu modelo soporte `decision_function` o `predict_proba`.\n","  if hasattr(modelo, \"decision_function\"):\n","      scores = modelo.decision_function(datos_prueba)\n","  else:\n","      scores = modelo.predict_proba(datos_prueba)[:, 1]\n","  auc = roc_auc_score(etiquetas_prueba, scores)\n","\n","\n","  current_data = {\n","    'Exactitud': exactitud * 100,\n","    'Sensibilidad': sensibilidad * 100,\n","    'Especificidad': especificidad * 100,\n","    'Precisión': precision * 100,\n","    'F1-Score': f1,\n","    'AUC': auc\n","  }\n","\n","  total_data.append(current_data)\n","\n","  #nombre_archivo_csv = '/content/drive/MyDrive/Estudios/Máster IIR/Segundo cuatrimestre/Proyecto VAI-AAI/first_version/hog.csv'\n","  nombre_archivo_csv = \"../results/lbp_combination_rf.csv\"\n","\n","\n","  with open(nombre_archivo_csv, 'a+', newline='') as archivo:\n","      es_vacio = archivo.tell() == 0\n","      escritor = csv.writer(archivo)\n","\n","      # Suponiendo que es_vacio indica si debemos escribir los encabezados\n","      if es_vacio:\n","          # Escribir los nombres de las claves del diccionario y luego los nombres de las métricas\n","          escritor.writerow(list(lbp_params.keys()) + list(current_data.keys()))\n","\n","      # Escribir los valores del diccionario y luego los valores de las métricas\n","      escritor.writerow(list(lbp_params.values()) + list(current_data.values()))\n","\n","  print(\"Datos guardados en el archivo CSV.\")\n","  print(\"Claves:\", list(lbp_params.keys()) + list(current_data.keys()))\n","  print(\"Valores:\", list(lbp_params.values()) + list(current_data.values()))\n","\n","  if len(total_data) == 3:\n","    if len(total_data) == len(combinaciones_lbp):\n","      # Encuentra el índice del mejor F1-Score\n","      index_mejor_f1 = max(range(len(total_data)), key=lambda i: total_data[i]['F1-Score'])\n","\n","      # Encuentra la configuración HOG correspondiente al mejor F1-Score\n","      lbp_correspondiente = combinaciones_lbp[index_mejor_f1]\n","\n","      for i in range(6, 10):\n","        data = {\n","          'radio': lbp_correspondiente['radio'],\n","          'n_puntos': i * lbp_correspondiente['radio'],\n","        }\n","        combinaciones_lbp.append(data)\n","\n"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
