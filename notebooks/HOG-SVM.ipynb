{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":953548,"status":"ok","timestamp":1710801638033,"user":{"displayName":"Anabel Díaz Labrador","userId":"11122352795951754174"},"user_tz":-60},"id":"dUCynuc_layU","outputId":"ce173230-53b2-4248-b027-e00bf10a7576"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Importar las bibliotecas necesarias\n","from sklearn import svm, metrics\n","from skimage.feature import hog\n","import numpy as np\n","import cv2\n","from os import listdir\n","from os.path import isfile, join\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n","import csv\n","import concurrent.futures\n","from sklearn.model_selection import StratifiedKFold\n","\n","path = '../data'\n","categorias = ['NORMAL', 'PNEUMONIA']\n","\n","total_data = []\n","\n","def procesar_imagen(imagen_path, size, etiqueta):\n","    imagen = cv2.imread(imagen_path, cv2.IMREAD_GRAYSCALE)\n","    if imagen is None:\n","        print(f'No se pudo leer la imagen: {imagen_path}')\n","        return None, None\n","\n","    imagen = cv2.resize(imagen, size)\n","    fd = hog(imagen, orientations=8, pixels_per_cell=(8, 8),\n","             cells_per_block=(1, 1), visualize=False)\n","\n","    return fd, etiqueta\n","\n","def cargar_datos(ruta, size=(128, 128)):\n","    datos = []\n","    etiquetas = []\n","    with concurrent.futures.ThreadPoolExecutor() as executor:\n","        futures = []\n","        for i, cat in enumerate(categorias):\n","            carpeta = join(ruta, cat)\n","            archivos = [f for f in listdir(carpeta) if isfile(join(carpeta, f))]\n","            for archivo in archivos:\n","                imagen_path = join(carpeta, archivo)\n","                futures.append(executor.submit(procesar_imagen, imagen_path, size, i))\n","\n","        for future in concurrent.futures.as_completed(futures):\n","            fd, label = future.result()\n","            if fd is not None:\n","                datos.append(fd)\n","                etiquetas.append(label)\n","\n","    if len(datos) == 0 or len(etiquetas) == 0:\n","        raise ValueError(\"No se pudieron cargar los datos. Asegúrate de que la ruta y las categorías son correctas.\")\n","\n","    return np.array(datos), np.array(etiquetas)\n","\n","\n","\n","# Cargar datos de entrenamiento, validación y prueba\n","datos, etiquetas = cargar_datos(join(path, 'train'))\n","\n","# Asegurarse de que hay datos para al menos dos clases\n","if len(np.unique(etiquetas)) < 2:\n","    raise ValueError(\"Se debe cargar datos para al menos dos clases en cada conjunto de datos.\")\n","\n","cv = StratifiedKFold(n_splits=5)\n","\n","#nombre_archivo_csv = '/content/drive/MyDrive/Proyecto VAI-AAI/first_version/cv_svm_hog.csv'\n","nombre_archivo_csv = '/content/drive/MyDrive/Estudios/Máster IIR/Segundo cuatrimestre/Proyecto VAI-AAI/first_version/cv_svm_hog.csv'\n","\n","# Preparar archivo CSV para guardar los resultados\n","with open(nombre_archivo_csv, 'a', newline='') as archivo_csv:\n","    es_vacio = archivo_csv.tell() == 0\n","    fieldnames = ['Fold', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","    writer = csv.DictWriter(archivo_csv, fieldnames=fieldnames)\n","    if es_vacio:\n","      writer.writeheader()\n","\n","    for fold, (train_index, val_index) in enumerate(cv.split(datos, etiquetas)):\n","        datos_entrenamiento, datos_prueba = datos[train_index], datos[val_index]\n","        etiquetas_entrenamiento, etiquetas_prueba = etiquetas[train_index], etiquetas[val_index]\n","\n","        # Crear y entrenar el modelo SVM\n","        modelo = svm.SVC(gamma='scale', probability=True)  # Asegúrate de activar probability=True para ROC AUC\n","        modelo.fit(datos_entrenamiento, etiquetas_entrenamiento)\n","\n","        # Evaluar el modelo\n","        etiquetas_predichas = modelo.predict(datos_prueba)\n","        exactitud = metrics.accuracy_score(etiquetas_prueba, etiquetas_predichas)\n","        cm = confusion_matrix(etiquetas_prueba, etiquetas_predichas)\n","        sensibilidad = recall_score(etiquetas_prueba, etiquetas_predichas)\n","        especificidad = cm[0,0] / (cm[0,0] + cm[0,1])\n","        precision = precision_score(etiquetas_prueba, etiquetas_predichas)\n","        f1 = f1_score(etiquetas_prueba, etiquetas_predichas)\n","\n","        # Calcular AUC\n","        if hasattr(modelo, \"decision_function\"):\n","            scores = modelo.decision_function(datos_prueba)\n","        else:\n","            scores = modelo.predict_proba(datos_prueba)[:, 1]\n","        auc = roc_auc_score(etiquetas_prueba, scores)\n","\n","        # Escribir resultados en el archivo CSV\n","        writer.writerow({\n","            'Fold': fold + 1,\n","            'Exactitud': exactitud * 100,\n","            'Sensibilidad': sensibilidad * 100,\n","            'Especificidad': especificidad * 100,\n","            'Precisión': precision * 100,\n","            'F1-Score': f1,\n","            'AUC': auc\n","        })\n","\n","# Cargar datos de prueba\n","datos_prueba, etiquetas_prueba = cargar_datos(join(path, 'test'))\n","\n","# Predecir etiquetas para el conjunto de prueba\n","etiquetas_predichas_prueba = modelo.predict(datos_prueba)\n","\n","# Calcular y mostrar métricas de rendimiento para el conjunto de prueba\n","exactitud_prueba = metrics.accuracy_score(etiquetas_prueba, etiquetas_predichas_prueba)\n","cm_prueba = confusion_matrix(etiquetas_prueba, etiquetas_predichas_prueba)\n","sensibilidad_prueba = recall_score(etiquetas_prueba, etiquetas_predichas_prueba)\n","especificidad_prueba = cm_prueba[0,0] / (cm_prueba[0,0] + cm_prueba[0,1])\n","precision_prueba = precision_score(etiquetas_prueba, etiquetas_predichas_prueba)\n","f1_prueba = f1_score(etiquetas_prueba, etiquetas_predichas_prueba)\n","\n","# Calcular AUC para el conjunto de prueba\n","if hasattr(modelo, \"decision_function\"):\n","    scores_prueba = modelo.decision_function(datos_prueba)\n","else:\n","    scores_prueba = modelo.predict_proba(datos_prueba)[:, 1]\n","auc_prueba = roc_auc_score(etiquetas_prueba, scores_prueba)\n","\n","with open(nombre_archivo_csv, 'a', newline='') as archivo_csv:  # 'a' para añadir al archivo existente\n","    fieldnames = ['Fold', 'Exactitud', 'Sensibilidad', 'Especificidad', 'Precisión', 'F1-Score', 'AUC']\n","    writer = csv.DictWriter(archivo_csv, fieldnames=fieldnames)\n","\n","    # No necesitamos volver a escribir el encabezado, asumiendo que estamos añadiendo al archivo existente\n","\n","    # Escribir resultados del conjunto de prueba en el archivo CSV\n","    writer.writerow({\n","        'Fold': 'Test',\n","        'Exactitud': exactitud_prueba * 100,\n","        'Sensibilidad': sensibilidad_prueba * 100,\n","        'Especificidad': especificidad_prueba * 100,\n","        'Precisión': precision_prueba * 100,\n","        'F1-Score': f1_prueba,\n","        'AUC': auc_prueba\n","    })"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
